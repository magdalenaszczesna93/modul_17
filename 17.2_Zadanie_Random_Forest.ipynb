{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Zadanie: Random Forest\n",
    "Podziel zbiór na treningowy i testowy, pamiętaj o stratyfikacji. Następnie naucz model Random Forest, z którego wyciągnij feature importance. Na podstawie tego wykonaj selekcję cech i weź jedynie te, których ważność jest większa niż 0.001. Nauczy nowy model Random Forest z wyborem hiperperparametrów, korzystając z GridSearch. Wykorzystaj poznane techniki do wektoryzacji.\n",
    "\n",
    "Wyniki prześlij Mentorowi jako Jupyter Notebook umieszczony w Twoim GitHubie."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import string\n",
    "import nltk\n",
    "import itertools\n",
    "from wordcloud import WordCloud\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spam                                               Text\n",
       "0        0  Go until jurong point, crazy.. Available only ...\n",
       "1        0                      Ok lar... Joking wif u oni...\n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...\n",
       "3        0  U dun say so early hor... U c already then say...\n",
       "4        0  Nah I don't think he goes to usf, he lives aro...\n",
       "...    ...                                                ...\n",
       "5567     1  This is the 2nd time we have tried 2 contact u...\n",
       "5568     0              Will Ì_ b going to esplanade fr home?\n",
       "5569     0  Pity, * was in mood for that. So...any other s...\n",
       "5570     0  The guy did some bitching but I acted like i'd...\n",
       "5571     0                         Rofl. Its true to its name\n",
       "\n",
       "[5572 rows x 2 columns]"
      ]
     },
     "execution_count": 209,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spam_dataset = pd.read_csv('spam.csv', encoding = \"ISO-8859-1\", usecols=[0, 1], \n",
    "                names=['Spam', 'Text'],\n",
    "                           skiprows=1)\n",
    "spam_dataset['Spam'] = spam_dataset['Spam'].replace(['ham', 'spam'], [0, 1])\n",
    "spam_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    0.865937\n",
      "1    0.134063\n",
      "Name: Spam, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "print(spam_dataset['Spam'].value_counts(normalize=True))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Usuwanie znaków interpunkcyjnych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>Will Ì b going to esplanade fr home</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Pity  was in mood for that Soany other suggest...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>The guy did some bitching but I acted like id ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spam                                               Text  \\\n",
       "0        0  Go until jurong point, crazy.. Available only ...   \n",
       "1        0                      Ok lar... Joking wif u oni...   \n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        0  U dun say so early hor... U c already then say...   \n",
       "4        0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567     1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568     0              Will Ì_ b going to esplanade fr home?   \n",
       "5569     0  Pity, * was in mood for that. So...any other s...   \n",
       "5570     0  The guy did some bitching but I acted like i'd...   \n",
       "5571     0                         Rofl. Its true to its name   \n",
       "\n",
       "                                           Cleaned_Text  \n",
       "0     Go until jurong point crazy Available only in ...  \n",
       "1                               Ok lar Joking wif u oni  \n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...  \n",
       "3           U dun say so early hor U c already then say  \n",
       "4     Nah I dont think he goes to usf he lives aroun...  \n",
       "...                                                 ...  \n",
       "5567  This is the 2nd time we have tried 2 contact u...  \n",
       "5568                Will Ì b going to esplanade fr home  \n",
       "5569  Pity  was in mood for that Soany other suggest...  \n",
       "5570  The guy did some bitching but I acted like id ...  \n",
       "5571                          Rofl Its true to its name  \n",
       "\n",
       "[5572 rows x 3 columns]"
      ]
     },
     "execution_count": 211,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def remove_puncation(text):\n",
    "    cleaned = ''.join([word for word in text if word not in string.punctuation])\n",
    "    return cleaned\n",
    "spam_dataset['Cleaned_Text'] = spam_dataset['Text'].apply(lambda x: remove_puncation(x))\n",
    "spam_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tokenizacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>Will Ì b going to esplanade fr home</td>\n",
       "      <td>[will, ì, b, going, to, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Pity  was in mood for that Soany other suggest...</td>\n",
       "      <td>[pity, was, in, mood, for, that, soany, other,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>The guy did some bitching but I acted like id ...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spam                                               Text  \\\n",
       "0        0  Go until jurong point, crazy.. Available only ...   \n",
       "1        0                      Ok lar... Joking wif u oni...   \n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        0  U dun say so early hor... U c already then say...   \n",
       "4        0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567     1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568     0              Will Ì_ b going to esplanade fr home?   \n",
       "5569     0  Pity, * was in mood for that. So...any other s...   \n",
       "5570     0  The guy did some bitching but I acted like i'd...   \n",
       "5571     0                         Rofl. Its true to its name   \n",
       "\n",
       "                                           Cleaned_Text  \\\n",
       "0     Go until jurong point crazy Available only in ...   \n",
       "1                               Ok lar Joking wif u oni   \n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3           U dun say so early hor U c already then say   \n",
       "4     Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                 ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u...   \n",
       "5568                Will Ì b going to esplanade fr home   \n",
       "5569  Pity  was in mood for that Soany other suggest...   \n",
       "5570  The guy did some bitching but I acted like id ...   \n",
       "5571                          Rofl Its true to its name   \n",
       "\n",
       "                                         Tokenized_Text  \n",
       "0     [go, until, jurong, point, crazy, available, o...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...  \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...  \n",
       "4     [nah, i, dont, think, he, goes, to, usf, he, l...  \n",
       "...                                                 ...  \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...  \n",
       "5568       [will, ì, b, going, to, esplanade, fr, home]  \n",
       "5569  [pity, was, in, mood, for, that, soany, other,...  \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...  \n",
       "5571                   [rofl, its, true, to, its, name]  \n",
       "\n",
       "[5572 rows x 4 columns]"
      ]
     },
     "execution_count": 212,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def tokenize(text):\n",
    "\n",
    "    # Usunięcie wielkich liter\n",
    "    clean_text = text.lower()\n",
    "\n",
    "    # Tokenizacja\n",
    "    tokenized_text = nltk.word_tokenize(clean_text)\n",
    "    return tokenized_text\n",
    "\n",
    "spam_dataset['Tokenized_Text'] = spam_dataset['Cleaned_Text'].apply(lambda x: tokenize(x))\n",
    "spam_dataset\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>WithoutStop_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, å£750, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>Will Ì b going to esplanade fr home</td>\n",
       "      <td>[will, ì, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ì, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Pity  was in mood for that Soany other suggest...</td>\n",
       "      <td>[pity, was, in, mood, for, that, soany, other,...</td>\n",
       "      <td>[pity, mood, soany, suggestions]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>The guy did some bitching but I acted like id ...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spam                                               Text  \\\n",
       "0        0  Go until jurong point, crazy.. Available only ...   \n",
       "1        0                      Ok lar... Joking wif u oni...   \n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        0  U dun say so early hor... U c already then say...   \n",
       "4        0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567     1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568     0              Will Ì_ b going to esplanade fr home?   \n",
       "5569     0  Pity, * was in mood for that. So...any other s...   \n",
       "5570     0  The guy did some bitching but I acted like i'd...   \n",
       "5571     0                         Rofl. Its true to its name   \n",
       "\n",
       "                                           Cleaned_Text  \\\n",
       "0     Go until jurong point crazy Available only in ...   \n",
       "1                               Ok lar Joking wif u oni   \n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3           U dun say so early hor U c already then say   \n",
       "4     Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                 ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u...   \n",
       "5568                Will Ì b going to esplanade fr home   \n",
       "5569  Pity  was in mood for that Soany other suggest...   \n",
       "5570  The guy did some bitching but I acted like id ...   \n",
       "5571                          Rofl Its true to its name   \n",
       "\n",
       "                                         Tokenized_Text  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568       [will, ì, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, soany, other,...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                       WithoutStop_Text  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4     [nah, dont, think, goes, usf, lives, around, t...  \n",
       "...                                                 ...  \n",
       "5567  [2nd, time, tried, 2, contact, u, u, å£750, po...  \n",
       "5568                 [ì, b, going, esplanade, fr, home]  \n",
       "5569                   [pity, mood, soany, suggestions]  \n",
       "5570  [guy, bitching, acted, like, id, interested, b...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 5 columns]"
      ]
     },
     "execution_count": 213,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords = nltk.corpus.stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    without_stopwords = [word for word in text if word not in stopwords]\n",
    "    return without_stopwords\n",
    "spam_dataset['WithoutStop_Text'] = spam_dataset['Tokenized_Text'].apply(lambda x: remove_stopwords(x))\n",
    "spam_dataset"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lematyzacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Spam</th>\n",
       "      <th>Text</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Tokenized_Text</th>\n",
       "      <th>WithoutStop_Text</th>\n",
       "      <th>Lemmatized_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>Go until jurong point, crazy.. Available only ...</td>\n",
       "      <td>Go until jurong point crazy Available only in ...</td>\n",
       "      <td>[go, until, jurong, point, crazy, available, o...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "      <td>[go, jurong, point, crazy, available, bugis, n...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Ok lar... Joking wif u oni...</td>\n",
       "      <td>Ok lar Joking wif u oni</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "      <td>[ok, lar, joking, wif, u, oni]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>Free entry in 2 a wkly comp to win FA Cup fina...</td>\n",
       "      <td>[free, entry, in, 2, a, wkly, comp, to, win, f...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "      <td>[free, entry, 2, wkly, comp, win, fa, cup, fin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>U dun say so early hor... U c already then say...</td>\n",
       "      <td>U dun say so early hor U c already then say</td>\n",
       "      <td>[u, dun, say, so, early, hor, u, c, already, t...</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "      <td>[u, dun, say, early, hor, u, c, already, say]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Nah I don't think he goes to usf, he lives aro...</td>\n",
       "      <td>Nah I dont think he goes to usf he lives aroun...</td>\n",
       "      <td>[nah, i, dont, think, he, goes, to, usf, he, l...</td>\n",
       "      <td>[nah, dont, think, goes, usf, lives, around, t...</td>\n",
       "      <td>[nah, dont, think, go, usf, life, around, though]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5567</th>\n",
       "      <td>1</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>This is the 2nd time we have tried 2 contact u...</td>\n",
       "      <td>[this, is, the, 2nd, time, we, have, tried, 2,...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, å£750, po...</td>\n",
       "      <td>[2nd, time, tried, 2, contact, u, u, å£750, po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5568</th>\n",
       "      <td>0</td>\n",
       "      <td>Will Ì_ b going to esplanade fr home?</td>\n",
       "      <td>Will Ì b going to esplanade fr home</td>\n",
       "      <td>[will, ì, b, going, to, esplanade, fr, home]</td>\n",
       "      <td>[ì, b, going, esplanade, fr, home]</td>\n",
       "      <td>[ì, b, going, esplanade, fr, home]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5569</th>\n",
       "      <td>0</td>\n",
       "      <td>Pity, * was in mood for that. So...any other s...</td>\n",
       "      <td>Pity  was in mood for that Soany other suggest...</td>\n",
       "      <td>[pity, was, in, mood, for, that, soany, other,...</td>\n",
       "      <td>[pity, mood, soany, suggestions]</td>\n",
       "      <td>[pity, mood, soany, suggestion]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5570</th>\n",
       "      <td>0</td>\n",
       "      <td>The guy did some bitching but I acted like i'd...</td>\n",
       "      <td>The guy did some bitching but I acted like id ...</td>\n",
       "      <td>[the, guy, did, some, bitching, but, i, acted,...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "      <td>[guy, bitching, acted, like, id, interested, b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5571</th>\n",
       "      <td>0</td>\n",
       "      <td>Rofl. Its true to its name</td>\n",
       "      <td>Rofl Its true to its name</td>\n",
       "      <td>[rofl, its, true, to, its, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "      <td>[rofl, true, name]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5572 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      Spam                                               Text  \\\n",
       "0        0  Go until jurong point, crazy.. Available only ...   \n",
       "1        0                      Ok lar... Joking wif u oni...   \n",
       "2        1  Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3        0  U dun say so early hor... U c already then say...   \n",
       "4        0  Nah I don't think he goes to usf, he lives aro...   \n",
       "...    ...                                                ...   \n",
       "5567     1  This is the 2nd time we have tried 2 contact u...   \n",
       "5568     0              Will Ì_ b going to esplanade fr home?   \n",
       "5569     0  Pity, * was in mood for that. So...any other s...   \n",
       "5570     0  The guy did some bitching but I acted like i'd...   \n",
       "5571     0                         Rofl. Its true to its name   \n",
       "\n",
       "                                           Cleaned_Text  \\\n",
       "0     Go until jurong point crazy Available only in ...   \n",
       "1                               Ok lar Joking wif u oni   \n",
       "2     Free entry in 2 a wkly comp to win FA Cup fina...   \n",
       "3           U dun say so early hor U c already then say   \n",
       "4     Nah I dont think he goes to usf he lives aroun...   \n",
       "...                                                 ...   \n",
       "5567  This is the 2nd time we have tried 2 contact u...   \n",
       "5568                Will Ì b going to esplanade fr home   \n",
       "5569  Pity  was in mood for that Soany other suggest...   \n",
       "5570  The guy did some bitching but I acted like id ...   \n",
       "5571                          Rofl Its true to its name   \n",
       "\n",
       "                                         Tokenized_Text  \\\n",
       "0     [go, until, jurong, point, crazy, available, o...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, in, 2, a, wkly, comp, to, win, f...   \n",
       "3     [u, dun, say, so, early, hor, u, c, already, t...   \n",
       "4     [nah, i, dont, think, he, goes, to, usf, he, l...   \n",
       "...                                                 ...   \n",
       "5567  [this, is, the, 2nd, time, we, have, tried, 2,...   \n",
       "5568       [will, ì, b, going, to, esplanade, fr, home]   \n",
       "5569  [pity, was, in, mood, for, that, soany, other,...   \n",
       "5570  [the, guy, did, some, bitching, but, i, acted,...   \n",
       "5571                   [rofl, its, true, to, its, name]   \n",
       "\n",
       "                                       WithoutStop_Text  \\\n",
       "0     [go, jurong, point, crazy, available, bugis, n...   \n",
       "1                        [ok, lar, joking, wif, u, oni]   \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...   \n",
       "3         [u, dun, say, early, hor, u, c, already, say]   \n",
       "4     [nah, dont, think, goes, usf, lives, around, t...   \n",
       "...                                                 ...   \n",
       "5567  [2nd, time, tried, 2, contact, u, u, å£750, po...   \n",
       "5568                 [ì, b, going, esplanade, fr, home]   \n",
       "5569                   [pity, mood, soany, suggestions]   \n",
       "5570  [guy, bitching, acted, like, id, interested, b...   \n",
       "5571                                 [rofl, true, name]   \n",
       "\n",
       "                                        Lemmatized_Text  \n",
       "0     [go, jurong, point, crazy, available, bugis, n...  \n",
       "1                        [ok, lar, joking, wif, u, oni]  \n",
       "2     [free, entry, 2, wkly, comp, win, fa, cup, fin...  \n",
       "3         [u, dun, say, early, hor, u, c, already, say]  \n",
       "4     [nah, dont, think, go, usf, life, around, though]  \n",
       "...                                                 ...  \n",
       "5567  [2nd, time, tried, 2, contact, u, u, å£750, po...  \n",
       "5568                 [ì, b, going, esplanade, fr, home]  \n",
       "5569                    [pity, mood, soany, suggestion]  \n",
       "5570  [guy, bitching, acted, like, id, interested, b...  \n",
       "5571                                 [rofl, true, name]  \n",
       "\n",
       "[5572 rows x 6 columns]"
      ]
     },
     "execution_count": 214,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lemmater = nltk.WordNetLemmatizer()\n",
    "def lemmatizing(text):\n",
    "    lemmatized_words = [lemmater.lemmatize(word) for word in text]\n",
    "    return lemmatized_words\n",
    "spam_dataset['Lemmatized_Text'] = spam_dataset['WithoutStop_Text'].apply(lambda x: lemmatizing(x))\n",
    "spam_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 8841)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "# define detaset\n",
    "tfidf = TfidfVectorizer()\n",
    "X = tfidf.fit_transform(spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x)))\n",
    "print(X.shape)\n",
    "y = spam_dataset['Spam']\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['008704050406', '0089my', '0121', ..., 'ûïharry', 'ûò', 'ûówell'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = tfidf.get_feature_names_out()\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treningowe obserwacje: 4457\n",
      "Testowe obserwacje: 1115\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                    random_state=42, stratify=y)\n",
    "print ('Treningowe obserwacje: %d\\nTestowe obserwacje: %d' % (X_train.shape[0], \n",
    "                                                                X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-7 {color: black;background-color: white;}#sk-container-id-7 pre{padding: 0;}#sk-container-id-7 div.sk-toggleable {background-color: white;}#sk-container-id-7 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-7 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-7 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-7 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-7 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-7 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-7 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-7 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-7 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-7 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-7 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-7 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-7 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-7 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-7 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-7 div.sk-item {position: relative;z-index: 1;}#sk-container-id-7 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-7 div.sk-item::before, #sk-container-id-7 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-7 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-7 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-7 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-7 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-7 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-7 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-7 div.sk-label-container {text-align: center;}#sk-container-id-7 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-7 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-7\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "RandomForestClassifier()"
      ]
     },
     "execution_count": 218,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "# define the model\n",
    "clf = RandomForestClassifier()\n",
    "#fit the model\n",
    "clf.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on training data: 1.0\n",
      "model score on testing data: 0.9766816143497757\n"
     ]
    }
   ],
   "source": [
    "print(f'model score on training data: {clf.score(X_train, y_train)}')\n",
    "print(f'model score on testing data: {clf.score(X_test, y_test)}')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Contrary to the testing set, the score on the training set is perfect, which means that our model is overfitting here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get importance\n",
    "importances = clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.08151593e-05, 3.68479994e-05, 1.31057009e-04, ...,\n",
       "       8.80853268e-05, 9.29887075e-06, 0.00000000e+00])"
      ]
     },
     "execution_count": 221,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.feature_importances_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = pd.DataFrame({'names':feature_names, 'importances':importances})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>names</th>\n",
       "      <th>importances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>0800</td>\n",
       "      <td>0.001763</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>08000839402</td>\n",
       "      <td>0.001810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>08000930705</td>\n",
       "      <td>0.003180</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>291</th>\n",
       "      <td>100</td>\n",
       "      <td>0.005590</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292</th>\n",
       "      <td>1000</td>\n",
       "      <td>0.008115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8406</th>\n",
       "      <td>weekly</td>\n",
       "      <td>0.002570</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8418</th>\n",
       "      <td>welcome</td>\n",
       "      <td>0.001012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8495</th>\n",
       "      <td>win</td>\n",
       "      <td>0.011967</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8504</th>\n",
       "      <td>winner</td>\n",
       "      <td>0.001831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8533</th>\n",
       "      <td>wkly</td>\n",
       "      <td>0.001535</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>161 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            names  importances\n",
       "48           0800     0.001763\n",
       "51    08000839402     0.001810\n",
       "52    08000930705     0.003180\n",
       "291           100     0.005590\n",
       "292          1000     0.008115\n",
       "...           ...          ...\n",
       "8406       weekly     0.002570\n",
       "8418      welcome     0.001012\n",
       "8495          win     0.011967\n",
       "8504       winner     0.001831\n",
       "8533         wkly     0.001535\n",
       "\n",
       "[161 rows x 2 columns]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "importances2 = features[features['importances']>0.001]\n",
    "importances2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameter: {'max_df': 0.3, 'min_df': 0.001, 'use_idf': True}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "Tfidf = TfidfVectorizer()\n",
    "parameters = {\n",
    "        'min_df': [0.001, 0.002, 0.003],\n",
    "        'max_df': [0.3, 0.4, 0.5],\n",
    "        'use_idf':[True, False]\n",
    "        }\n",
    "gridsearch = GridSearchCV(Tfidf,\n",
    "                             parameters,\n",
    "                             scoring='f1_macro')\n",
    "gridsearch.fit(spam_dataset)\n",
    "print('\\nBest hyperparameter:', gridsearch.best_params_)\n",
    "Tfdif_grid = gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 1364)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "tfidf2 = TfidfVectorizer(max_df = 0.3, min_df = 0.001, use_idf = True)\n",
    "X = tfidf2.fit_transform(spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x)))\n",
    "print(X.shape)\n",
    "y = spam_dataset['Spam']\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Treningowe obserwacje: 4457\n",
      "Testowe obserwacje: 1115\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, \n",
    "                                    random_state=42, stratify=y)\n",
    "print ('Treningowe obserwacje: %d\\nTestowe obserwacje: %d' % (X_train.shape[0], \n",
    "                                                                X_test.shape[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best hyperparameter: {'max_depth': 15, 'min_samples_leaf': 1, 'n_estimators': 100}\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "clf_2 = RandomForestClassifier()\n",
    "parameters = {\n",
    "        'max_depth': [5, 10, 15],\n",
    "        'min_samples_leaf': [1, 3, 5],\n",
    "        'n_estimators':[100, 500, 1000]\n",
    "        }\n",
    "gridsearch = GridSearchCV(clf_2,\n",
    "                        parameters,\n",
    "                        scoring='f1_macro'\n",
    "                        )\n",
    "gridsearch.fit(X_train, y_train)\n",
    "print('\\nBest hyperparameter:', gridsearch.best_params_)\n",
    "clf_2_grid = gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9183856502242153"
      ]
     },
     "execution_count": 284,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "clf_2 = RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_leaf=1, random_state=0)\n",
    "clf_2.fit(X_train, y_train)\n",
    "clf_2.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model score on training data: 0.9322414179941665\n",
      "model score on testing data: 0.9183856502242153\n"
     ]
    }
   ],
   "source": [
    "print(f'model score on training data: {clf_2.score(X_train, y_train)}')\n",
    "print(f'model score on testing data: {clf_2.score(X_test, y_test)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9294687724335966"
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_3 = RandomForestClassifier(n_estimators=100, max_depth=15, min_samples_leaf=1, random_state=0)\n",
    "clf_3.fit(X, y)\n",
    "clf_2.score(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5572, 1364)\n",
      "(5572,)\n"
     ]
    }
   ],
   "source": [
    "tfidf2 = TfidfVectorizer(max_df=0.5, min_df=0.001, use_idf=True)\n",
    "X = tfidf.fit_transform(spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x)))\n",
    "print(X.shape)\n",
    "y = spam_dataset['Spam']\n",
    "print(y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5572x1364 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 35142 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count = CountVectorizer(max_df = 0.3, min_df = 0.001)\n",
    "X_count = count.fit_transform(spam_dataset['Lemmatized_Text'].apply(lambda x: ' '.join(x)))\n",
    "X_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'go': 495,\n",
       " 'point': 901,\n",
       " 'crazy': 295,\n",
       " 'available': 136,\n",
       " 'bugis': 198,\n",
       " 'great': 507,\n",
       " 'world': 1325,\n",
       " 'la': 635,\n",
       " 'cine': 246,\n",
       " 'got': 504,\n",
       " 'wat': 1273,\n",
       " 'ok': 829,\n",
       " 'lar': 640,\n",
       " 'joking': 613,\n",
       " 'wif': 1299,\n",
       " 'free': 461,\n",
       " 'entry': 395,\n",
       " 'wkly': 1313,\n",
       " 'comp': 266,\n",
       " 'win': 1303,\n",
       " 'cup': 299,\n",
       " 'final': 438,\n",
       " 'may': 726,\n",
       " 'text': 1153,\n",
       " 'receive': 947,\n",
       " 'txt': 1218,\n",
       " 'apply': 115,\n",
       " 'dun': 369,\n",
       " 'say': 992,\n",
       " 'early': 373,\n",
       " 'already': 97,\n",
       " 'nah': 790,\n",
       " 'dont': 356,\n",
       " 'think': 1164,\n",
       " 'usf': 1241,\n",
       " 'life': 665,\n",
       " 'around': 123,\n",
       " 'though': 1170,\n",
       " 'freemsg': 462,\n",
       " 'hey': 543,\n",
       " 'darling': 313,\n",
       " 'week': 1283,\n",
       " 'word': 1321,\n",
       " 'back': 148,\n",
       " 'id': 578,\n",
       " 'like': 668,\n",
       " 'fun': 476,\n",
       " 'still': 1103,\n",
       " 'xxx': 1339,\n",
       " 'std': 1102,\n",
       " 'send': 1012,\n",
       " '150': 19,\n",
       " 'even': 399,\n",
       " 'brother': 192,\n",
       " 'speak': 1083,\n",
       " 'treat': 1203,\n",
       " 'per': 869,\n",
       " 'request': 962,\n",
       " 'set': 1019,\n",
       " 'caller': 206,\n",
       " 'press': 912,\n",
       " 'copy': 282,\n",
       " 'friend': 467,\n",
       " 'winner': 1305,\n",
       " 'valued': 1248,\n",
       " 'network': 799,\n",
       " 'customer': 302,\n",
       " 'selected': 1008,\n",
       " '900': 62,\n",
       " 'prize': 917,\n",
       " 'reward': 967,\n",
       " 'claim': 248,\n",
       " 'call': 204,\n",
       " 'code': 255,\n",
       " 'valid': 1247,\n",
       " '12': 16,\n",
       " 'hour': 566,\n",
       " 'mobile': 759,\n",
       " '11': 14,\n",
       " 'month': 768,\n",
       " 'entitled': 394,\n",
       " 'update': 1233,\n",
       " 'latest': 644,\n",
       " 'colour': 262,\n",
       " 'camera': 210,\n",
       " 'co': 254,\n",
       " 'im': 583,\n",
       " 'gon': 499,\n",
       " 'na': 789,\n",
       " 'home': 558,\n",
       " 'soon': 1077,\n",
       " 'want': 1267,\n",
       " 'talk': 1135,\n",
       " 'stuff': 1112,\n",
       " 'anymore': 108,\n",
       " 'tonight': 1189,\n",
       " 'ive': 604,\n",
       " 'enough': 391,\n",
       " 'today': 1183,\n",
       " 'chance': 228,\n",
       " 'cash': 220,\n",
       " '100': 9,\n",
       " 'pound': 908,\n",
       " 'cost': 284,\n",
       " '16': 24,\n",
       " 'reply': 959,\n",
       " 'hl': 549,\n",
       " 'info': 592,\n",
       " 'urgent': 1236,\n",
       " 'tc': 1140,\n",
       " 'pobox': 898,\n",
       " 'right': 968,\n",
       " 'thank': 1156,\n",
       " 'promise': 922,\n",
       " 'wont': 1320,\n",
       " 'take': 1133,\n",
       " 'help': 542,\n",
       " 'wonderful': 1318,\n",
       " 'time': 1177,\n",
       " 'date': 316,\n",
       " 'sunday': 1119,\n",
       " 'use': 1238,\n",
       " 'credit': 296,\n",
       " 'click': 251,\n",
       " 'wap': 1269,\n",
       " 'link': 671,\n",
       " 'next': 804,\n",
       " 'message': 741,\n",
       " 'oh': 828,\n",
       " 'watching': 1275,\n",
       " 'eh': 380,\n",
       " 'remember': 954,\n",
       " 'name': 792,\n",
       " 'yes': 1348,\n",
       " 'naughty': 795,\n",
       " 'make': 714,\n",
       " 'fine': 441,\n",
       " 'way': 1278,\n",
       " 'feel': 431,\n",
       " 'england': 389,\n",
       " 'miss': 751,\n",
       " 'news': 803,\n",
       " 'ur': 1234,\n",
       " 'national': 793,\n",
       " 'team': 1143,\n",
       " 'eg': 378,\n",
       " 'seriously': 1017,\n",
       " 'going': 498,\n",
       " 'try': 1210,\n",
       " 'ha': 517,\n",
       " 'pay': 865,\n",
       " 'first': 445,\n",
       " 'da': 306,\n",
       " 'comin': 264,\n",
       " 'aft': 79,\n",
       " 'finish': 443,\n",
       " 'lunch': 709,\n",
       " 'lor': 691,\n",
       " 'ard': 118,\n",
       " 'smth': 1066,\n",
       " 'alright': 98,\n",
       " 'meet': 734,\n",
       " 'eat': 375,\n",
       " 'really': 944,\n",
       " 'hungry': 574,\n",
       " 'tho': 1169,\n",
       " 'suck': 1116,\n",
       " 'mark': 719,\n",
       " 'getting': 489,\n",
       " 'worried': 1326,\n",
       " 'know': 632,\n",
       " 'sick': 1038,\n",
       " 'turn': 1215,\n",
       " 'pizza': 883,\n",
       " 'lol': 684,\n",
       " 'always': 101,\n",
       " 'catch': 223,\n",
       " 'bus': 199,\n",
       " 'egg': 379,\n",
       " 'tea': 1141,\n",
       " 'eating': 377,\n",
       " 'mom': 763,\n",
       " 'left': 656,\n",
       " 'dinner': 340,\n",
       " 'love': 696,\n",
       " 'amp': 102,\n",
       " 'car': 215,\n",
       " 'ill': 582,\n",
       " 'let': 661,\n",
       " 'there': 1161,\n",
       " 'room': 975,\n",
       " 'work': 1322,\n",
       " 'wait': 1260,\n",
       " 'thats': 1159,\n",
       " 'sure': 1126,\n",
       " 'doesnt': 350,\n",
       " 'live': 675,\n",
       " 'yeah': 1345,\n",
       " 'child': 242,\n",
       " 'till': 1176,\n",
       " 'cheer': 239,\n",
       " 'tell': 1147,\n",
       " 'anything': 110,\n",
       " 'quick': 929,\n",
       " 'thanks': 1157,\n",
       " 'ringtone': 970,\n",
       " 'uk': 1225,\n",
       " 'charged': 233,\n",
       " 'please': 890,\n",
       " 'confirm': 273,\n",
       " 'replying': 960,\n",
       " 'yup': 1360,\n",
       " 'look': 688,\n",
       " 'timing': 1178,\n",
       " 'msg': 779,\n",
       " 'learn': 651,\n",
       " '2nd': 36,\n",
       " 'lesson': 660,\n",
       " 'oops': 838,\n",
       " 'roommate': 976,\n",
       " 'done': 355,\n",
       " 'see': 1004,\n",
       " 'letter': 662,\n",
       " 'decide': 323,\n",
       " 'hello': 541,\n",
       " 'hows': 569,\n",
       " 'saturday': 988,\n",
       " 'texting': 1154,\n",
       " 'youd': 1355,\n",
       " 'decided': 324,\n",
       " 'tomo': 1186,\n",
       " 'trying': 1211,\n",
       " 'pls': 893,\n",
       " 'ahead': 86,\n",
       " 'wanted': 1268,\n",
       " 'weekend': 1284,\n",
       " 'abiola': 63,\n",
       " 'forget': 455,\n",
       " 'need': 797,\n",
       " 'crave': 294,\n",
       " 'sweet': 1129,\n",
       " 'tried': 1204,\n",
       " 'sm': 1061,\n",
       " 'nokia': 813,\n",
       " 'camcorder': 208,\n",
       " '08000930705': 2,\n",
       " 'delivery': 329,\n",
       " 'tomorrow': 1187,\n",
       " 'seeing': 1005,\n",
       " 'hope': 560,\n",
       " 'man': 716,\n",
       " 'well': 1288,\n",
       " 'ltgt': 705,\n",
       " 'inch': 589,\n",
       " 'didnt': 333,\n",
       " 'get': 487,\n",
       " 'nigeria': 807,\n",
       " 'tyler': 1221,\n",
       " 'cant': 214,\n",
       " 'could': 287,\n",
       " 'maybe': 728,\n",
       " 'ask': 128,\n",
       " 'bit': 173,\n",
       " 'hospital': 563,\n",
       " 'kept': 622,\n",
       " 'telling': 1148,\n",
       " 'saw': 991,\n",
       " 'class': 249,\n",
       " 'usually': 1244,\n",
       " 'run': 981,\n",
       " 'half': 521,\n",
       " 'almost': 95,\n",
       " 'whole': 1297,\n",
       " 'second': 1001,\n",
       " 'fyi': 479,\n",
       " 'morning': 771,\n",
       " 'he': 533,\n",
       " 'place': 884,\n",
       " 'wow': 1332,\n",
       " 'never': 801,\n",
       " 'thought': 1171,\n",
       " 'liked': 669,\n",
       " 'since': 1046,\n",
       " 'best': 167,\n",
       " 'happy': 529,\n",
       " 'sorry': 1078,\n",
       " 'give': 492,\n",
       " 'new': 802,\n",
       " 'play': 888,\n",
       " 'ice': 577,\n",
       " 'correct': 283,\n",
       " 'end': 385,\n",
       " 'yesterday': 1350,\n",
       " 'find': 440,\n",
       " 'congrats': 274,\n",
       " 'year': 1346,\n",
       " 'special': 1084,\n",
       " 'cinema': 247,\n",
       " 'pas': 862,\n",
       " 'etc': 397,\n",
       " '150pm': 21,\n",
       " 'later': 643,\n",
       " 'meeting': 735,\n",
       " 'reached': 938,\n",
       " 'pick': 876,\n",
       " 'move': 773,\n",
       " 'pain': 855,\n",
       " 'good': 501,\n",
       " 'joke': 612,\n",
       " 'girl': 491,\n",
       " 'situation': 1053,\n",
       " 'part': 859,\n",
       " 'checking': 238,\n",
       " 'took': 1191,\n",
       " 'forever': 454,\n",
       " 'come': 263,\n",
       " 'double': 358,\n",
       " 'check': 236,\n",
       " 'hair': 520,\n",
       " 'said': 985,\n",
       " 'wun': 1335,\n",
       " 'cut': 303,\n",
       " 'short': 1032,\n",
       " 'nice': 806,\n",
       " 'pleased': 891,\n",
       " 'following': 451,\n",
       " 'review': 966,\n",
       " 'mob': 758,\n",
       " 'awarded': 142,\n",
       " 'bonus': 178,\n",
       " 'song': 1075,\n",
       " 'day': 318,\n",
       " 'frnds': 471,\n",
       " 'rply': 979,\n",
       " 'complimentary': 270,\n",
       " 'trip': 1205,\n",
       " '1000': 10,\n",
       " 'dis': 344,\n",
       " 'hear': 535,\n",
       " 'lucky': 708,\n",
       " 'save': 990,\n",
       " 'money': 767,\n",
       " 'hee': 539,\n",
       " 'finished': 444,\n",
       " 'hi': 545,\n",
       " 'babe': 146,\n",
       " 'wan': 1265,\n",
       " 'something': 1072,\n",
       " 'xx': 1338,\n",
       " 'waiting': 1261,\n",
       " 'cool': 281,\n",
       " 'people': 868,\n",
       " 'much': 781,\n",
       " 'pa': 852,\n",
       " 'looking': 690,\n",
       " 'job': 608,\n",
       " 'ta': 1132,\n",
       " 'ah': 84,\n",
       " 'stop': 1105,\n",
       " 'real': 943,\n",
       " 'yo': 1353,\n",
       " 'ticket': 1174,\n",
       " 'one': 835,\n",
       " 'used': 1239,\n",
       " 'started': 1096,\n",
       " 'came': 209,\n",
       " 'bed': 163,\n",
       " 'download': 359,\n",
       " 'wen': 1289,\n",
       " 'stand': 1093,\n",
       " 'close': 252,\n",
       " 'll': 676,\n",
       " 'another': 106,\n",
       " 'night': 808,\n",
       " 'spent': 1088,\n",
       " 'late': 642,\n",
       " 'afternoon': 80,\n",
       " 'mean': 729,\n",
       " 'havent': 532,\n",
       " 'smile': 1063,\n",
       " 'pleasure': 892,\n",
       " 'trouble': 1206,\n",
       " 'rain': 932,\n",
       " 'hurt': 576,\n",
       " 'someone': 1071,\n",
       " 'smiling': 1064,\n",
       " 'service': 1018,\n",
       " 'representative': 961,\n",
       " '0800': 0,\n",
       " 'guaranteed': 511,\n",
       " '5000': 50,\n",
       " 'planning': 887,\n",
       " 'buy': 201,\n",
       " '530': 51,\n",
       " 'show': 1033,\n",
       " 'simply': 1045,\n",
       " 'password': 863,\n",
       " 'abt': 65,\n",
       " 'load': 678,\n",
       " 'loan': 679,\n",
       " 'wk': 1312,\n",
       " 'forgot': 456,\n",
       " 'shower': 1034,\n",
       " 'cause': 224,\n",
       " 'prob': 918,\n",
       " 'nothing': 818,\n",
       " 'else': 382,\n",
       " 'okay': 830,\n",
       " 'price': 914,\n",
       " 'long': 686,\n",
       " 'ave': 137,\n",
       " 'gone': 500,\n",
       " 'driving': 364,\n",
       " 'test': 1152,\n",
       " 'yet': 1351,\n",
       " 'youre': 1357,\n",
       " 'guess': 513,\n",
       " 'gave': 483,\n",
       " 'men': 739,\n",
       " 'changed': 230,\n",
       " 'search': 999,\n",
       " 'location': 681,\n",
       " 'cuz': 305,\n",
       " 'page': 853,\n",
       " 'umma': 1226,\n",
       " 'lot': 694,\n",
       " 'dear': 322,\n",
       " 'wish': 1306,\n",
       " 'birthday': 172,\n",
       " 'making': 715,\n",
       " 'aight': 88,\n",
       " 'hit': 547,\n",
       " 'would': 1331,\n",
       " 'address': 75,\n",
       " 'computer': 271,\n",
       " 'isnt': 602,\n",
       " 'old': 832,\n",
       " 'better': 168,\n",
       " 'worry': 1327,\n",
       " 'busy': 200,\n",
       " 'thing': 1163,\n",
       " 'mah': 712,\n",
       " 'contact': 277,\n",
       " 'last': 641,\n",
       " 'draw': 360,\n",
       " '12hrs': 17,\n",
       " '150ppm': 23,\n",
       " 'anyway': 112,\n",
       " 'juz': 616,\n",
       " 'eatin': 376,\n",
       " 'happened': 525,\n",
       " 'entered': 393,\n",
       " 'bday': 160,\n",
       " 'bos': 183,\n",
       " 'felt': 433,\n",
       " 'askd': 129,\n",
       " 'invited': 598,\n",
       " 'apartment': 113,\n",
       " 'went': 1290,\n",
       " 'specially': 1086,\n",
       " 'holiday': 556,\n",
       " 'flight': 449,\n",
       " 'inc': 588,\n",
       " 'operator': 840,\n",
       " '18': 25,\n",
       " 'must': 787,\n",
       " 'friday': 466,\n",
       " 'uncle': 1227,\n",
       " 'paying': 866,\n",
       " 'school': 995,\n",
       " 'directly': 343,\n",
       " 'food': 453,\n",
       " 'private': 916,\n",
       " '2004': 31,\n",
       " 'account': 68,\n",
       " 'statement': 1098,\n",
       " 'unredeemed': 1231,\n",
       " 'identifier': 580,\n",
       " 'expires': 413,\n",
       " '2000': 29,\n",
       " 'landline': 638,\n",
       " 'number': 822,\n",
       " 'ending': 387,\n",
       " '350': 41,\n",
       " 'award': 141,\n",
       " 'match': 722,\n",
       " '08712300220': 5,\n",
       " 'standard': 1094,\n",
       " 'rate': 934,\n",
       " 'app': 114,\n",
       " 'mu': 780,\n",
       " 'ìï': 1362,\n",
       " 'buying': 202,\n",
       " 'sent': 1015,\n",
       " 'bother': 184,\n",
       " 'sending': 1013,\n",
       " 'del': 328,\n",
       " 'bak': 151,\n",
       " 'answer': 107,\n",
       " 'question': 928,\n",
       " 'sunshine': 1121,\n",
       " 'quiz': 931,\n",
       " 'top': 1192,\n",
       " 'sony': 1076,\n",
       " 'dvd': 371,\n",
       " 'player': 889,\n",
       " 'country': 288,\n",
       " 'dogging': 352,\n",
       " 'direct': 342,\n",
       " 'join': 610,\n",
       " 'bt': 194,\n",
       " 'txting': 1219,\n",
       " 'nt': 820,\n",
       " 'haf': 518,\n",
       " 'youll': 1356,\n",
       " 'chat': 234,\n",
       " 'age': 82,\n",
       " 'yr': 1359,\n",
       " 'lazy': 646,\n",
       " 'type': 1222,\n",
       " 'lect': 655,\n",
       " 'sir': 1049,\n",
       " 'mail': 713,\n",
       " 'tired': 1179,\n",
       " 'little': 674,\n",
       " 'lovable': 695,\n",
       " 'person': 870,\n",
       " 'heart': 537,\n",
       " 'gud': 512,\n",
       " 'ni8': 805,\n",
       " 'open': 839,\n",
       " 'ya': 1341,\n",
       " 'whats': 1292,\n",
       " 'taking': 1134,\n",
       " 'replied': 958,\n",
       " 'sexy': 1022,\n",
       " 'local': 680,\n",
       " 'luv': 710,\n",
       " 'ltd': 703,\n",
       " 'begin': 165,\n",
       " 'pray': 910,\n",
       " 'hard': 530,\n",
       " 'ki': 624,\n",
       " 'wine': 1304,\n",
       " 'thk': 1167,\n",
       " 'shirt': 1028,\n",
       " 'sometimes': 1073,\n",
       " 'dream': 361,\n",
       " 'without': 1310,\n",
       " 'joy': 614,\n",
       " 'tv': 1216,\n",
       " 'become': 162,\n",
       " 'leaving': 654,\n",
       " 'house': 567,\n",
       " 'boy': 187,\n",
       " 'missing': 753,\n",
       " 'arrange': 124,\n",
       " 'keep': 620,\n",
       " 'safe': 984,\n",
       " 'everyone': 403,\n",
       " 'hand': 522,\n",
       " 'spend': 1087,\n",
       " 'inviting': 599,\n",
       " 'frnd': 470,\n",
       " '62468': 53,\n",
       " 'order': 846,\n",
       " 'content': 278,\n",
       " 'goto': 505,\n",
       " 'wit': 1308,\n",
       " 'fancy': 421,\n",
       " 'completely': 269,\n",
       " 'also': 100,\n",
       " 'waste': 1272,\n",
       " 'bank': 153,\n",
       " 'hmmm': 551,\n",
       " 'muz': 788,\n",
       " 'liao': 663,\n",
       " 'coming': 265,\n",
       " 'hell': 540,\n",
       " 'believe': 166,\n",
       " 'mr': 776,\n",
       " 'bath': 155,\n",
       " 'youve': 1358,\n",
       " 'carlos': 218,\n",
       " 'staying': 1101,\n",
       " 'til': 1175,\n",
       " 'smoke': 1065,\n",
       " 'worth': 1329,\n",
       " 'log': 682,\n",
       " 'spoke': 1089,\n",
       " 'wed': 1280,\n",
       " 'experience': 412,\n",
       " 'offer': 825,\n",
       " 'especially': 396,\n",
       " 'studying': 1111,\n",
       " 'gr8': 506,\n",
       " 'trust': 1208,\n",
       " 'guy': 515,\n",
       " 'working': 1324,\n",
       " 'towards': 1198,\n",
       " 'net': 798,\n",
       " 'wheres': 1294,\n",
       " 'boytoy': 188,\n",
       " 'haha': 519,\n",
       " 'awesome': 144,\n",
       " 'minute': 749,\n",
       " 'freephone': 463,\n",
       " 'xmas': 1337,\n",
       " 'jus': 615,\n",
       " 'bathe': 156,\n",
       " 'si': 1037,\n",
       " 'using': 1242,\n",
       " 'joined': 611,\n",
       " 'touch': 1195,\n",
       " 'deal': 321,\n",
       " 'personal': 871,\n",
       " 'finally': 439,\n",
       " 'course': 290,\n",
       " 'however': 568,\n",
       " 'stay': 1100,\n",
       " 'able': 64,\n",
       " 'every': 402,\n",
       " 'mrng': 777,\n",
       " 'hav': 531,\n",
       " 'story': 1107,\n",
       " 'dead': 320,\n",
       " 'tmr': 1180,\n",
       " 'orchard': 845,\n",
       " 'mrt': 778,\n",
       " 'kate': 618,\n",
       " 'evening': 400,\n",
       " 'found': 459,\n",
       " 'buck': 196,\n",
       " 'darlin': 312,\n",
       " 'college': 261,\n",
       " 'ltdecimalgt': 704,\n",
       " 'balance': 152,\n",
       " 'goodmorning': 502,\n",
       " 'sleeping': 1057,\n",
       " 'dat': 315,\n",
       " 'oso': 848,\n",
       " 'oredi': 847,\n",
       " 'connection': 276,\n",
       " 'bill': 170,\n",
       " 'big': 169,\n",
       " 'ready': 942,\n",
       " 'break': 190,\n",
       " 'semester': 1011,\n",
       " 'noe': 812,\n",
       " 'leh': 657,\n",
       " 'sound': 1080,\n",
       " 'slept': 1058,\n",
       " 'past': 864,\n",
       " 'easy': 374,\n",
       " 'exam': 408,\n",
       " 'march': 718,\n",
       " 'gt': 510,\n",
       " 'called': 205,\n",
       " 'important': 587,\n",
       " 'file': 435,\n",
       " 'system': 1131,\n",
       " 'shop': 1030,\n",
       " 'happen': 524,\n",
       " 'nite': 809,\n",
       " '500': 49,\n",
       " 'collect': 259,\n",
       " 'appreciate': 116,\n",
       " 'partner': 860,\n",
       " 'start': 1095,\n",
       " 'sign': 1041,\n",
       " 'company': 267,\n",
       " 'po': 897,\n",
       " 'bcoz': 159,\n",
       " 'teach': 1142,\n",
       " 'walk': 1263,\n",
       " 'road': 972,\n",
       " 'side': 1039,\n",
       " 'street': 1108,\n",
       " 'battery': 157,\n",
       " 'died': 335,\n",
       " '10p': 12,\n",
       " 'wil': 1301,\n",
       " 'reach': 937,\n",
       " 'argument': 121,\n",
       " 'kick': 625,\n",
       " 'secret': 1002,\n",
       " 'admirer': 76,\n",
       " 'ufind': 1223,\n",
       " 'rreveal': 980,\n",
       " 'specialcall': 1085,\n",
       " 'laptop': 639,\n",
       " 'case': 219,\n",
       " 'tel': 1146,\n",
       " 'meant': 731,\n",
       " 'told': 1185,\n",
       " 'face': 416,\n",
       " 'watch': 1274,\n",
       " 'fr': 460,\n",
       " 'thanx': 1158,\n",
       " 'everything': 404,\n",
       " 'uve': 1245,\n",
       " 'asked': 130,\n",
       " 'kallis': 617,\n",
       " 'goodnight': 503,\n",
       " 'fix': 447,\n",
       " 'wake': 1262,\n",
       " 'missed': 752,\n",
       " 'sleep': 1056,\n",
       " 'congratulation': 275,\n",
       " 'cd': 226,\n",
       " 'voucher': 1257,\n",
       " 'music': 786,\n",
       " '87066': 60,\n",
       " 'tncs': 1181,\n",
       " 'cal': 203,\n",
       " 'hold': 553,\n",
       " 'angry': 104,\n",
       " 'wid': 1298,\n",
       " 'dnt': 347,\n",
       " 'coz': 292,\n",
       " 'true': 1207,\n",
       " 'showing': 1035,\n",
       " 'deep': 326,\n",
       " 'care': 217,\n",
       " 'lem': 659,\n",
       " 'lover': 699,\n",
       " 'video': 1251,\n",
       " 'handset': 523,\n",
       " '750': 54,\n",
       " 'anytime': 111,\n",
       " 'min': 746,\n",
       " 'unlimited': 1230,\n",
       " 'shopping': 1031,\n",
       " 'disturb': 346,\n",
       " 'ring': 969,\n",
       " 'horny': 562,\n",
       " 'naked': 791,\n",
       " 'hot': 564,\n",
       " 'unsubscribe': 1232,\n",
       " 'dint': 341,\n",
       " 'wana': 1266,\n",
       " 'plan': 885,\n",
       " 'choose': 244,\n",
       " 'club': 253,\n",
       " 'single': 1047,\n",
       " 'quality': 927,\n",
       " 'charge': 232,\n",
       " 'ended': 386,\n",
       " 'sunny': 1120,\n",
       " 'leaf': 650,\n",
       " 'blue': 175,\n",
       " '86688': 59,\n",
       " 'might': 745,\n",
       " 'full': 474,\n",
       " 'swing': 1130,\n",
       " 'far': 424,\n",
       " 'okie': 831,\n",
       " 'usual': 1243,\n",
       " 'baby': 147,\n",
       " 'fone': 452,\n",
       " 'ge': 486,\n",
       " 'sense': 1014,\n",
       " 'stupid': 1113,\n",
       " 'phone': 873,\n",
       " 'sim': 1043,\n",
       " 'card': 216,\n",
       " 'loyalty': 702,\n",
       " 'unless': 1229,\n",
       " 'die': 334,\n",
       " 'plz': 895,\n",
       " 'rose': 977,\n",
       " 'bslvyl': 193,\n",
       " 'coffee': 256,\n",
       " 'somebody': 1070,\n",
       " 'high': 546,\n",
       " 'shit': 1029,\n",
       " 'imagine': 584,\n",
       " 'somewhere': 1074,\n",
       " '4u': 47,\n",
       " 'book': 180,\n",
       " 'friendship': 468,\n",
       " 'game': 481,\n",
       " 'tone': 1188,\n",
       " 'sport': 1090,\n",
       " 'key': 623,\n",
       " 'arent': 120,\n",
       " 'accept': 66,\n",
       " 'sister': 1050,\n",
       " '200': 28,\n",
       " 'weekly': 1285,\n",
       " 'box': 186,\n",
       " 'definitely': 327,\n",
       " '2day': 35,\n",
       " 'normal': 817,\n",
       " 'rest': 963,\n",
       " 'wot': 1330,\n",
       " 'lost': 693,\n",
       " 'made': 711,\n",
       " 'kb': 619,\n",
       " 'power': 909,\n",
       " 'yoga': 1354,\n",
       " 'dunno': 370,\n",
       " 'dude': 367,\n",
       " '11mths': 15,\n",
       " 'merry': 740,\n",
       " 'christmas': 245,\n",
       " 'kiss': 630,\n",
       " 'pete': 872,\n",
       " 'problem': 920,\n",
       " 'track': 1200,\n",
       " 'record': 949,\n",
       " 'reading': 941,\n",
       " 'woman': 1316,\n",
       " 'read': 940,\n",
       " 'light': 667,\n",
       " 'movie': 774,\n",
       " 'return': 965,\n",
       " 'immediately': 586,\n",
       " 'fixed': 448,\n",
       " 'line': 670,\n",
       " 'via': 1250,\n",
       " 'access': 67,\n",
       " 'valentine': 1246,\n",
       " '150pmsg': 22,\n",
       " 'rcvd': 936,\n",
       " 'calling': 207,\n",
       " 'post': 906,\n",
       " 'wiv': 1311,\n",
       " 'interested': 596,\n",
       " 'two': 1217,\n",
       " 'round': 978,\n",
       " 'yijue': 1352,\n",
       " 'small': 1062,\n",
       " 'txts': 1220,\n",
       " 'ever': 401,\n",
       " 'urself': 1237,\n",
       " 'fault': 428,\n",
       " 'figure': 434,\n",
       " 'jay': 607,\n",
       " 'weed': 1282,\n",
       " 'ish': 601,\n",
       " 'ago': 83,\n",
       " 'met': 742,\n",
       " 'ex': 406,\n",
       " 'cashbalance': 221,\n",
       " 'currently': 300,\n",
       " 'maximize': 725,\n",
       " 'cashin': 222,\n",
       " 'cc': 225,\n",
       " 'hgsuite3422lands': 544,\n",
       " 'moment': 764,\n",
       " 'st': 1092,\n",
       " 'cold': 257,\n",
       " 'posted': 907,\n",
       " 'chikku': 241,\n",
       " 'forward': 457,\n",
       " 'air': 90,\n",
       " 'motorola': 772,\n",
       " 'bluetooth': 176,\n",
       " 'orange': 844,\n",
       " 'mobileupd8': 760,\n",
       " '08000839402': 1,\n",
       " 'discount': 345,\n",
       " 'woke': 1315,\n",
       " 'talking': 1136,\n",
       " 'willing': 1302,\n",
       " 'reference': 950,\n",
       " 'seen': 1007,\n",
       " 'mei': 737,\n",
       " 'happening': 526,\n",
       " 'sigh': 1040,\n",
       " 'project': 921,\n",
       " 'mistake': 754,\n",
       " 'quite': 930,\n",
       " 'slow': 1059,\n",
       " 'guide': 514,\n",
       " 'relax': 953,\n",
       " 'reason': 945,\n",
       " 'couple': 289,\n",
       " 'leave': 653,\n",
       " 'mm': 755,\n",
       " 'rental': 957,\n",
       " 'huh': 573,\n",
       " 'sat': 987,\n",
       " 'pilate': 880,\n",
       " 'office': 826,\n",
       " 'bout': 185,\n",
       " 'actually': 71,\n",
       " 'rock': 973,\n",
       " 'putting': 926,\n",
       " 'put': 925,\n",
       " 'picture': 879,\n",
       " 'as': 126,\n",
       " 'facebook': 417,\n",
       " 'al': 93,\n",
       " 'god': 496,\n",
       " 'india': 590,\n",
       " 'change': 229,\n",
       " 'dai': 309,\n",
       " 'poly': 902,\n",
       " '1st': 26,\n",
       " 'yep': 1347,\n",
       " 'pm': 896,\n",
       " 'drink': 362,\n",
       " 'fullonsmscom': 475,\n",
       " 'den': 330,\n",
       " 'bring': 191,\n",
       " 'dating': 317,\n",
       " '250': 33,\n",
       " 'head': 534,\n",
       " 'eve': 398,\n",
       " 'yahoo': 1342,\n",
       " 'ad': 72,\n",
       " '150p': 20,\n",
       " 'aha': 85,\n",
       " 'land': 637,\n",
       " '3030': 40,\n",
       " 'voice': 1256,\n",
       " 'shell': 1026,\n",
       " 'mind': 747,\n",
       " 'giving': 493,\n",
       " 'lift': 666,\n",
       " 'wnt': 1314,\n",
       " 'vry': 1258,\n",
       " 'fucking': 473,\n",
       " 'vary': 1249,\n",
       " 'ldn': 647,\n",
       " 'booked': 181,\n",
       " 'th': 1155,\n",
       " 'askin': 131,\n",
       " 'dollar': 354,\n",
       " 'ten': 1149,\n",
       " '50': 48,\n",
       " 'tough': 1196,\n",
       " 'supposed': 1125,\n",
       " 'tot': 1194,\n",
       " 'din': 339,\n",
       " 'group': 509,\n",
       " 'kinda': 628,\n",
       " 'hmm': 550,\n",
       " '10': 8,\n",
       " 'detail': 332,\n",
       " 'welcome': 1287,\n",
       " 'ure': 1235,\n",
       " 'beautiful': 161,\n",
       " 'result': 964,\n",
       " 'kind': 627,\n",
       " 'asking': 132,\n",
       " 'ttyl': 1213,\n",
       " 'bad': 149,\n",
       " 'thru': 1172,\n",
       " 'different': 336,\n",
       " 'decision': 325,\n",
       " 'optout': 843,\n",
       " 'princess': 915,\n",
       " 'style': 1114,\n",
       " 'enjoy': 390,\n",
       " 'many': 717,\n",
       " 'notice': 819,\n",
       " 'tenerife': 1150,\n",
       " 'sae': 983,\n",
       " 'remove': 955,\n",
       " 'moan': 757,\n",
       " 'cum': 298,\n",
       " '8th': 61,\n",
       " 'thinking': 1166,\n",
       " 'sec': 1000,\n",
       " 'fb': 429,\n",
       " 'activate': 70,\n",
       " 'term': 1151,\n",
       " 'condition': 272,\n",
       " 'visit': 1253,\n",
       " 'depends': 331,\n",
       " 'meh': 736,\n",
       " 'nope': 815,\n",
       " 'monday': 766,\n",
       " 'either': 381,\n",
       " 'lose': 692,\n",
       " 'water': 1276,\n",
       " 'bored': 182,\n",
       " 'outside': 851,\n",
       " 'park': 858,\n",
       " 'near': 796,\n",
       " 'rent': 956,\n",
       " 'opinion': 841,\n",
       " 'silent': 1042,\n",
       " 'character': 231,\n",
       " 'simple': 1044,\n",
       " 'tat': 1139,\n",
       " '40gb': 44,\n",
       " 'ipod': 600,\n",
       " 'mp3': 775,\n",
       " 'pin': 881,\n",
       " 'le': 648,\n",
       " 'fri': 465,\n",
       " 'adult': 77,\n",
       " 'shall': 1023,\n",
       " 'campus': 211,\n",
       " 'attempt': 134,\n",
       " '85023': 57,\n",
       " ...}"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count.vocabulary_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8659368269921034"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf_v2 = RandomForestClassifier(max_depth=2, random_state=0)\n",
    "clf_v2.fit(X_count, y)\n",
    "clf_v2.score(X_count, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]\n",
      " [0 0 0 ... 0 0 0]]\n"
     ]
    }
   ],
   "source": [
    "print(X_count.toarray()[:5])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "a491fa038a24a3354ef15b8320e5eed1f98c46448a463343d2ea596d5b86218b"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
